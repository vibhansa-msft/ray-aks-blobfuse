# ========== RAY DATA PREPARATION JOB ==========
# This RayJob specification configures a Ray cluster for data preparation tasks
# Designed to run various data preparation scripts (prepare_data.py)
#
# Key features:
#   - CPU-only worker nodes optimized for data processing
#   - Azure Blob Storage integration for data output
#   - Distributed Ray cluster for parallel data processing
#   - Flexible dataset download and Parquet conversion

apiVersion: ray.io/v1
kind: RayJob

# ========== METADATA ==========

metadata:
  name: model-training-job

# ========== RAY JOB SPECIFICATION ==========

spec:
  # ===== Job Configuration =====
  
  # Shutdown the Ray cluster when job finishes
  shutdownAfterJobFinishes: true
  
  # TTL for automatic cleanup - delete job 30 minutes after completion
  ttlSecondsAfterFinished: 1800
  
  # Entry point command - can be customized for different datasets
  entrypoint: "python /app/train_minimal.py"

  # Runtime environment variables and dependencies
  runtimeEnvYAML: |
    pip:
      - torch>=2.1.0
      - transformers>=4.35.0
      - datasets>=2.14.5
      - pyarrow>=14.0.0
      - pandas>=2.0.0
      - bitsandbytes>=0.41.0
      - numpy>=1.24.0
      - accelerate>=0.24.0
      - sentencepiece>=0.1.99
      - ray[tune]>=2.50.0
    env_vars:
      DATA_DIR: "__DATA_DIR__"
      CHECKPOINT_DIR: "__CHECKPOINT_DIR__"
      APP_DIR: "__APP_DIR__"
      NUM_WORKERS: "__NUM_WORKERS__"
      NUM_SAMPLES: "12"
      PYTHONPATH: "__APP_DIR__"
      TRANSFORMERS_OFFLINE: "0"
      HF_TOKEN: "__HF_TOKEN__"

  # ========== RAY CLUSTER SPECIFICATION ==========

  rayClusterSpec:
    # Ray version - uses official Ray image from Docker Hub
    rayVersion: "2.50.0"

    # ===== HEAD NODE CONFIGURATION =====
    # Single head node that coordinates the distributed cluster
    
    headGroupSpec:
      serviceType: ClusterIP
      # Enable Ray Dashboard
      rayStartParams:
        dashboard-host: "0.0.0.0"
        include-dashboard: "true"
        dashboard-port: "8265"
      template:
        spec:
          initContainers:
          - name: setup-blobfuse-cache
            image: busybox:1.28
            command: ['mkdir', '-p', '__CHECKPOINT_DIR__']
            resources:
              requests:
                cpu: "100m"
                memory: "128Mi"
              limits:
                cpu: "200m"
                memory: "256Mi"
            volumeMounts:
              - name: blob-checkpoints
                mountPath: __CHECKPOINT_DIR__
          containers:
          - name: ray-head
            # Standard Ray image with Python support
            image: rayproject/ray:2.50.0
            
            # Resource requests for proper scheduling and autoscaling
            resources:
              requests:
                cpu: "8000m"      # 8 CPU cores for head node (need for model caching)
                memory: "64Gi"    # 64GB memory for model downloading and caching
              limits:
                cpu: "16000m"     # Max 16 CPU cores
                memory: "128Gi"   # Max 128GB memory
            
            # Ray object spilling configuration for memory management
            env:
              - name: RAY_OBJECT_SPILLING_CONFIG
                value: |
                  {"type":"filesystem","params":{"directory_path":"/tmp/ray_spill"}}
            
           # Mount Azure Blob Storage for dataset and checkpoints
            volumeMounts:
              - name: blob-dataset
                mountPath: "__DATA_DIR__"
                readOnly: true
              - name: blob-checkpoints
                mountPath: "__CHECKPOINT_DIR__"
              - name: app-code
                mountPath: "__APP_DIR__"
              - name: cache-dir
                mountPath: "__CACHE_DIR__"
          
          # Persistent volumes for Azure Blob Storage
          volumes:
            - name: blob-dataset
              persistentVolumeClaim:
                claimName: blob-pvc-dataset
                readOnly: true
            - name: blob-checkpoints
              persistentVolumeClaim:
                claimName: blob-pvc-checkpoint
            - name: app-code
              configMap:
                name: hpo-app-code
                defaultMode: 0755
            - name: cache-dir
              emptyDir: {}

    # ===== CPU WORKER NODES CONFIGURATION =====
    # Worker nodes optimized for data processing tasks
    
    workerGroupSpecs:
    - groupName: data-workers
      replicas: __WORKER_REPLICAS__
      template:
        spec:
          initContainers:
          - name: setup-blobfuse-cache
            image: busybox:1.28
            command: ['mkdir', '-p', '__CACHE_DIR__']
            resources:
              requests:
                cpu: "100m"
                memory: "128Mi"
              limits:
                cpu: "200m"
                memory: "256Mi"
            volumeMounts:
              - name: cache-dir
                mountPath: /mnt
          containers:
          - name: ray-worker
            # Standard Ray image with Python support
            image: rayproject/ray:2.50.0
            
            # Resource requests for proper scheduling and autoscaling
            # D48ds_v5: 48 vCPU, 192GB RAM per node
            # 23 nodes × 2 workers per node ≈ 40 workers
            # Per worker allocation: 22 vCPU, 90GB RAM (leaving headroom for system)
            resources:
              requests:
                cpu: "22000m"     # 22 vCPU per worker (48/2 = 24, request 22 for headroom)
                memory: "90Gi"    # 90GB per worker (192/2 = 96, request 90 for headroom)
              limits:
                cpu: "24000m"     # Max 24 vCPU per worker (full 48/2)
                memory: "96Gi"    # Max 96GB per worker (full 192/2)
            
            # Ray object spilling for memory management
            env:
              - name: RAY_OBJECT_SPILLING_CONFIG
                value: |
                  {"type":"filesystem","params":{"directory_path":"/tmp/ray_spill"}}
            
            # Mount Azure Blob Storage for dataset and checkpoints
            volumeMounts:
              - name: blob-dataset
                mountPath: "__DATA_DIR__"
                readOnly: true
              - name: blob-checkpoints
                mountPath: "__CHECKPOINT_DIR__"
              - name: app-code
                mountPath: "__APP_DIR__"
              - name: cache-dir
                mountPath: "__CACHE_DIR__"
          
          # Persistent volumes for Azure Blob Storage
          volumes:
            - name: blob-dataset
              persistentVolumeClaim:
                claimName: blob-pvc-dataset
                readOnly: true
            - name: blob-checkpoints
              persistentVolumeClaim:
                claimName: blob-pvc-checkpoint
            - name: app-code
              configMap:
                name: hpo-app-code
                defaultMode: 0755
            - name: cache-dir
              emptyDir: {}
# ========== RAY HPO JOB (CPU) ==========
# This RayJob specification configures a distributed Ray cluster for CPU-only
# hyperparameter optimization of the DistilBERT model on the AG News dataset.
#
# Key features:
#   - CPU-only worker nodes for cost-effective distributed training
#   - Distributed Ray cluster with head and worker nodes
#   - Azure Blob Storage integration via Blobfuse2 mount
#   - Object spilling for memory-intensive operations
#   - Auto-scaling worker nodes (1-100 replicas)
#   - Standard Ray 2.50.0 image with Python 3.11

apiVersion: ray.io/v1
kind: RayJob

# ========== METADATA ==========

metadata:
  name: hpo-job-cpu

# ========== RAY JOB SPECIFICATION ==========

spec:
  # ===== Job Configuration =====
  selector:
    matchLabels:
      component: ray-worker

  template:
    metadata:
      labels:
        component: ray-worker
        ray.io/node-type: worker 
        
  # Shutdown the Ray cluster when job finishes
  shutdownAfterJobFinishes: true
  
  # TTL for automatic cleanup - delete job 30 minutes after completion
  ttlSecondsAfterFinished: 1800
  
  # Entry point command executed on Ray job submit
  entrypoint: "python /app/train_hpo.py"

  # Runtime environment variables and dependencies
  runtimeEnvYAML: |
    pip:
      - torch==2.1.0
      - transformers==4.36.0
      - datasets==2.16.0
      - pyarrow==14.0.0
    env_vars:
      DATA_DIR: "__DATA_DIR__"
      CHECKPOINT_DIR: "__CHECKPOINT_DIR__"
      CHECKPOINT_CACHE: "__CHECKPOINT_CACHE__"
      APP_DIR: "__APP_DIR__"
      NUM_WORKERS: "__NUM_WORKERS__"
      NUM_SAMPLES: "12"
      PYTHONPATH: "__APP_DIR__"

  # ========== RAY CLUSTER SPECIFICATION ==========

  rayClusterSpec:
    # Ray version - uses official Ray image from Docker Hub
    rayVersion: "2.50.0"

    # ===== HEAD NODE CONFIGURATION =====
    # Single head node that coordinates the distributed cluster
    
    headGroupSpec:
      serviceType: ClusterIP
      # Enable Ray Dashboard
      rayStartParams:
        dashboard-host: "0.0.0.0"
        include-dashboard: "true"
        dashboard-port: "8265"
      template:
        spec:
          initContainers:
          - name: setup-cache-directories
            image: busybox:1.28
            command: ['sh', '-c', 'mkdir -p __CACHE_DIR__ && mkdir -p __CHECKPOINT_CACHE__']
            resources:
              requests:
                cpu: "100m"
                memory: "128Mi"
              limits:
                cpu: "200m"
                memory: "256Mi"
            volumeMounts:
              - name: cache-dir
                mountPath: __CACHE_DIR__
              - name: checkpoint-cache-dir
                mountPath: __CHECKPOINT_CACHE__
          containers:
          - name: ray-head
            # Standard Ray image with Python support
            image: rayproject/ray:2.50.0
            
            # Resource requests for proper scheduling and autoscaling
            resources:
              requests:
                cpu: "8000m"       # 8 CPU cores for head node
                memory: "16Gi"     # 16GB memory for head node
              limits:
                cpu: "16000m"      # Max 16 CPU cores
                memory: "32Gi"     # Max 32GB memory
            
            # Ray object spilling configuration for memory management
            env:
              - name: RAY_OBJECT_SPILLING_CONFIG
                value: |
                  {"type":"filesystem","params":{"directory_path":"/tmp/ray_spill"}}
              - name: TUNE_WARN_SLOW_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S
                value: "300"
              - name: RAY_TRAIN_TORCH_BACKEND
                value: "nccl"
            
            # Mount Azure Blob Storage for dataset and checkpoints
            volumeMounts:
              - name: blob-dataset
                mountPath: "__DATA_DIR__"
                readOnly: true
              - name: blob-checkpoints
                mountPath: "__CHECKPOINT_DIR__"
              - name: app-code
                mountPath: "__APP_DIR__"
              - name: cache-dir
                mountPath: "__CACHE_DIR__"
              - name: checkpoint-cache-dir
                mountPath: "__CHECKPOINT_CACHE__"
          
          # Persistent volumes for Azure Blob Storage
          volumes:
            - name: blob-dataset
              persistentVolumeClaim:
                claimName: blob-pvc-dataset
                readOnly: true
            - name: blob-checkpoints
              persistentVolumeClaim:
                claimName: blob-pvc-checkpoint
            - name: app-code
              configMap:
                name: hpo-app-code
                defaultMode: 0755
            - name: cache-dir
              emptyDir: {}
            - name: checkpoint-cache-dir
              emptyDir: {}

    # ===== CPU WORKER NODES CONFIGURATION =====
    # Worker nodes that execute distributed training tasks
    # CPU workers can auto-scale based on demand
    
    workerGroupSpecs:
    - groupName: cpu-group
      replicas: __WORKER_REPLICAS__
      # Auto-scaling configuration (can scale down to 1, up to 100 replicas)
      # minReplicas: 1
      # maxReplicas: 100
      template:
        spec:
          affinity:
            podAntiAffinity:
              requiredDuringSchedulingIgnoredDuringExecution:
                - labelSelector:
                    matchLabels:    
                      ray.io/cluster: hpo-job-cpu
                      ray.io/group-name: cpu-group
                    topologyKey: "kubernetes.io/hostname" # Enforce anti-affinity at the node level

          initContainers:
          - name: setup-cache-directories
            image: busybox:1.28
            command: ['sh', '-c', 'mkdir -p __CACHE_DIR__ && mkdir -p __CHECKPOINT_CACHE__']
            resources:
              requests:
                cpu: "100m"
                memory: "128Mi"
              limits:
                cpu: "200m"
                memory: "256Mi"
            volumeMounts:
              - name: cache-dir
                mountPath: __CACHE_DIR__
              - name: checkpoint-cache-dir
                mountPath: __CHECKPOINT_CACHE__
          containers:
          - name: ray-worker
            # Standard Ray image with Python support
            image: rayproject/ray:2.50.0
            
            # Resource requests for proper scheduling and autoscaling
            resources:
              requests:
                cpu: "40000m"      # 45 CPU cores per worker
                memory: "120Gi"     # 140GB memory per worker
              limits:
                cpu: "40000m"      # 45 CPU cores per worker
                memory: "120Gi"     # 140GB memory per worker
            command: ["/bin/bash", "-c"]
              args:
                - |
                  # The operator automatically sets RAY_ADDRESS to point to the head service.
                  ray start --address=$RAY_ADDRESS --block \
                      --num-cpus=40 \
                      --memory=120Gi \
                      --object-store-memory=80Gi        

            # Ray object spilling for memory management
            env:
              - name: RAY_OBJECT_SPILLING_CONFIG
                value: |
                  {"type":"filesystem","params":{"directory_path":"/tmp/ray_spill"}}
              - name: TUNE_WARN_SLOW_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S
                value: "300"
            
            # Mount Azure Blob Storage for dataset and checkpoints
            volumeMounts:
              - name: blob-dataset
                mountPath: "__DATA_DIR__"
                readOnly: true
              - name: blob-checkpoints
                mountPath: "__CHECKPOINT_DIR__"
              - name: app-code
                mountPath: "__APP_DIR__"
              - name: cache-dir
                mountPath: "__CACHE_DIR__"
              - name: checkpoint-cache-dir
                mountPath: "__CHECKPOINT_CACHE__"
          
          # Persistent volumes for Azure Blob Storage
          volumes:
            - name: blob-dataset
              persistentVolumeClaim:
                claimName: blob-pvc-dataset
                readOnly: true
            - name: blob-checkpoints
              persistentVolumeClaim:
                claimName: blob-pvc-checkpoint
            - name: app-code
              configMap:
                name: hpo-app-code
                defaultMode: 0755
            - name: cache-dir
              emptyDir: {}
            - name: checkpoint-cache-dir
              emptyDir: {}

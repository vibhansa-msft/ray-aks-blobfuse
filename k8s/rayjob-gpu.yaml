# ========== RAY HPO JOB (GPU) ==========
# This RayJob specification configures a distributed Ray cluster for GPU-accelerated
# hyperparameter optimization of the DistilBERT model on the AG News dataset.
#
# Key features:
#   - GPU worker nodes for accelerated training
#   - Distributed Ray cluster with head and worker nodes
#   - Azure Blob Storage integration via Blobfuse2 mount
#   - Object spilling for memory-intensive operations
#   - GPU node affinity via taints and tolerations
#   - Standard Ray 2.50.0 GPU image with CUDA support

apiVersion: ray.io/v1
kind: RayJob

# ========== METADATA ==========

metadata:
  name: hpo-job-gpu

# ========== RAY JOB SPECIFICATION ==========

spec:
  # ===== Job Configuration =====
  
  # Entry point command executed on Ray job submit
  entrypoint: "python /app/train_hpo.py"

  # Runtime environment variables and dependencies
  runtimeEnvYAML: |
    pip:
      - torch==2.1.0
      - transformers==4.36.0
      - datasets==2.16.0
      - pyarrow==14.0.0
    env_vars:
      DATA_DIR: /mnt/blob/datasets
      CHECKPOINT_DIR: /mnt/blob/checkpoints
      NUM_WORKERS: "__NUM_WORKERS__"
      NUM_SAMPLES: "12"
      PYTHONPATH: /app

  # ========== RAY CLUSTER SPECIFICATION ==========

  rayClusterSpec:
    # Ray version - uses official Ray GPU image from Docker Hub
    rayVersion: "2.50.0"

    # ===== HEAD NODE CONFIGURATION =====
    # Single head node that coordinates the distributed cluster
    
    headGroupSpec:
      serviceType: ClusterIP
      template:
        spec:
          initContainers:
          - name: setup-blobfuse-cache
            image: busybox:1.28
            command: ['mkdir', '-p', '/mnt/blobfusecache']
            volumeMounts:
              - name: cache-dir
                mountPath: /mnt
          containers:
          - name: ray-head
            # Standard Ray GPU image with CUDA support
            image: rayproject/ray:2.50.0-gpu
            
            # Ray object spilling configuration for memory management
            env:
              - name: RAY_OBJECT_SPILLING_CONFIG
                value: |
                  {"type":"filesystem","params":{"directory_path":"/tmp/ray_spill"}}
            
            # Mount Azure Blob Storage for dataset and checkpoints
            volumeMounts:
              - name: blob-dataset
                mountPath: /mnt/blob/datasets
                readOnly: true
              - name: blob-checkpoints
                mountPath: /mnt/blob/checkpoints
              - name: app-code
                mountPath: /app
              - name: cache-dir
                mountPath: /mnt/blobfusecache
          
          # Persistent volumes for Azure Blob Storage
          volumes:
            - name: blob-dataset
              persistentVolumeClaim:
                claimName: blob-pvc-dataset
                readOnly: true
            - name: blob-checkpoints
              persistentVolumeClaim:
                claimName: blob-pvc-checkpoint
            - name: app-code
              configMap:
                name: hpo-app-code
                defaultMode: 0755
            - name: cache-dir
              emptyDir: {}

    # ===== GPU WORKER NODES CONFIGURATION =====
    # Worker nodes that execute distributed training tasks
    
    workerGroupSpecs:
    - groupName: gpu-group
      replicas: __WORKER_REPLICAS__
      template:
        spec:
          initContainers:
          - name: setup-blobfuse-cache
            image: busybox:1.28
            command: ['mkdir', '-p', '/mnt/blobfusecache']
            volumeMounts:
              - name: cache-dir
                mountPath: /mnt
          # GPU node selection via tolerations
          # Tolerates the gpu:NoSchedule taint set on GPU node pools
          tolerations:
          - key: "sku"
            operator: "Equal"
            value: "gpu"
            effect: "NoSchedule"
          
          containers:
          - name: ray-worker
            # Standard Ray GPU image with CUDA support
            image: rayproject/ray:2.50.0-gpu
            
            # GPU resource requirements (1 GPU per worker pod)
            resources:
              limits:
                nvidia.com/gpu: "1"
            
            # Ray object spilling for memory management
            env:
              - name: RAY_OBJECT_SPILLING_CONFIG
                value: |
                  {"type":"filesystem","params":{"directory_path":"/tmp/ray_spill"}}
            
            # Mount Azure Blob Storage for dataset and checkpoints
            volumeMounts:
              - name: blob-dataset
                mountPath: /mnt/blob/datasets
                readOnly: true
              - name: blob-checkpoints
                mountPath: /mnt/blob/checkpoints
              - name: app-code
                mountPath: /app
              - name: cache-dir
                mountPath: /mnt/blobfusecache
          
          # Persistent volumes for Azure Blob Storage
          volumes:
            - name: blob-dataset
              persistentVolumeClaim:
                claimName: blob-pvc-dataset
                readOnly: true
            - name: blob-checkpoints
              persistentVolumeClaim:
                claimName: blob-pvc-checkpoint
            - name: app-code
              configMap:
                name: hpo-app-code
                defaultMode: 0755
            - name: cache-dir
              emptyDir: {}
